{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/lgcnmodel/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from config import CFG, logging_conf\n",
    "from lightgcn.datasets import prepare_dataset\n",
    "from lightgcn.models import build, train\n",
    "from lightgcn.utils import class2dict, get_logger\n",
    "\n",
    "from lightgcn.datasets import prepare_dataset\n",
    "from lightgcn.models import build, inference\n",
    "from lightgcn.utils import get_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger(logging_conf)\n",
    "use_cuda = torch.cuda.is_available() and CFG.use_cuda_if_available\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(basepath):\n",
    "    path1 = os.path.join(basepath, \"train_data.csv\")\n",
    "    path2 = os.path.join(basepath, \"test_data.csv\")\n",
    "    data1 = pd.read_csv(path1)\n",
    "    data2 = pd.read_csv(path2)\n",
    "\n",
    "    data = pd.concat([data1, data2])\n",
    "    data.drop_duplicates(\n",
    "        subset=[\"userID\", \"assessmentItemID\"], keep=\"last\", inplace=True\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def separate_data(data):\n",
    "    train_data = data[data.answerCode >= 0]\n",
    "    test_data = data[data.answerCode < 0]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def indexing_data(data):\n",
    "    userid, itemid = (\n",
    "        sorted(list(set(data.userID))),\n",
    "        sorted(list(set(data.assessmentItemID))),\n",
    "    )\n",
    "    n_user, n_item = len(userid), len(itemid)\n",
    "\n",
    "    userid_2_index = {v: i for i, v in enumerate(userid)}\n",
    "    itemid_2_index = {v: i + n_user for i, v in enumerate(itemid)}\n",
    "    id_2_index = dict(userid_2_index, **itemid_2_index)\n",
    "\n",
    "    return id_2_index\n",
    "\n",
    "\n",
    "def process_data(data, id_2_index, device):\n",
    "    edge, label = [], []\n",
    "    for user, item, acode in zip(data.userID, data.assessmentItemID, data.answerCode):\n",
    "        uid, iid = id_2_index[user], id_2_index[item]\n",
    "        edge.append([uid, iid])\n",
    "        label.append(acode)\n",
    "\n",
    "    edge = torch.LongTensor(edge).T\n",
    "    label = torch.LongTensor(label)\n",
    "\n",
    "    return dict(edge=edge.to(device), label=label.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(device, basepath, verbose=True, logger=None):\n",
    "    data = load_data(basepath)\n",
    "    train_data, test_data = separate_data(data)\n",
    "    id2index = indexing_data(data)\n",
    "    train_data_proc = process_data(train_data, id2index, device)\n",
    "    test_data_proc = process_data(test_data, id2index, device)\n",
    "\n",
    "    # if verbose:\n",
    "    #     print_data_stat(train_data, \"Train\", logger=logger)\n",
    "    #     print_data_stat(test_data, \"Test\", logger=logger)\n",
    "\n",
    "    return train_data_proc, test_data_proc, len(id2index), id2index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepare\n",
    "train_data, test_data, n_node, edge_index = prepare_dataset(\n",
    "    device, CFG.basepath, verbose=CFG.loader_verbose, logger=logger.getChild(\"data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-28 07:26:38,826 - build - INFO - No load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGCN(16896, 64, num_layers=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model build\n",
    "model = build(\n",
    "    n_node,\n",
    "    embedding_dim=CFG.embedding_dim,\n",
    "    num_layers=CFG.num_layers,\n",
    "    alpha=CFG.alpha,\n",
    "    logger=logger.getChild(\"build\"),\n",
    "    **CFG.build_kwargs\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-28 07:26:39,109 - train - INFO - Training Started : n_epoch=20\n",
      "2022-11-28 07:26:39,148 - train - INFO -  * In epoch 0001, loss=0.693, acc=0.528, AUC=0.526\n",
      "2022-11-28 07:26:39,149 - train - INFO -  * In epoch 0001, loss=0.693, acc=0.528, AUC=0.526, Best AUC\n",
      "2022-11-28 07:26:39,207 - train - INFO -  * In epoch 0002, loss=0.693, acc=0.538, AUC=0.546\n",
      "2022-11-28 07:26:39,209 - train - INFO -  * In epoch 0002, loss=0.693, acc=0.538, AUC=0.546, Best AUC\n",
      "2022-11-28 07:26:39,266 - train - INFO -  * In epoch 0003, loss=0.693, acc=0.549, AUC=0.567\n",
      "2022-11-28 07:26:39,268 - train - INFO -  * In epoch 0003, loss=0.693, acc=0.549, AUC=0.567, Best AUC\n",
      "2022-11-28 07:26:39,325 - train - INFO -  * In epoch 0004, loss=0.693, acc=0.560, AUC=0.588\n",
      "2022-11-28 07:26:39,327 - train - INFO -  * In epoch 0004, loss=0.693, acc=0.560, AUC=0.588, Best AUC\n",
      "2022-11-28 07:26:39,382 - train - INFO -  * In epoch 0005, loss=0.693, acc=0.586, AUC=0.609\n",
      "2022-11-28 07:26:39,384 - train - INFO -  * In epoch 0005, loss=0.693, acc=0.586, AUC=0.609, Best AUC\n",
      "2022-11-28 07:26:39,438 - train - INFO -  * In epoch 0006, loss=0.693, acc=0.603, AUC=0.630\n",
      "2022-11-28 07:26:39,440 - train - INFO -  * In epoch 0006, loss=0.693, acc=0.603, AUC=0.630, Best AUC\n",
      "2022-11-28 07:26:39,494 - train - INFO -  * In epoch 0007, loss=0.693, acc=0.619, AUC=0.653\n",
      "2022-11-28 07:26:39,496 - train - INFO -  * In epoch 0007, loss=0.693, acc=0.619, AUC=0.653, Best AUC\n",
      "2022-11-28 07:26:39,550 - train - INFO -  * In epoch 0008, loss=0.693, acc=0.633, AUC=0.675\n",
      "2022-11-28 07:26:39,552 - train - INFO -  * In epoch 0008, loss=0.693, acc=0.633, AUC=0.675, Best AUC\n",
      "2022-11-28 07:26:39,606 - train - INFO -  * In epoch 0009, loss=0.693, acc=0.654, AUC=0.697\n",
      "2022-11-28 07:26:39,608 - train - INFO -  * In epoch 0009, loss=0.693, acc=0.654, AUC=0.697, Best AUC\n",
      "2022-11-28 07:26:39,657 - train - INFO -  * In epoch 0010, loss=0.693, acc=0.680, AUC=0.719\n",
      "2022-11-28 07:26:39,659 - train - INFO -  * In epoch 0010, loss=0.693, acc=0.680, AUC=0.719, Best AUC\n",
      "2022-11-28 07:26:39,709 - train - INFO -  * In epoch 0011, loss=0.693, acc=0.701, AUC=0.739\n",
      "2022-11-28 07:26:39,711 - train - INFO -  * In epoch 0011, loss=0.693, acc=0.701, AUC=0.739, Best AUC\n",
      "2022-11-28 07:26:39,762 - train - INFO -  * In epoch 0012, loss=0.693, acc=0.715, AUC=0.758\n",
      "2022-11-28 07:26:39,763 - train - INFO -  * In epoch 0012, loss=0.693, acc=0.715, AUC=0.758, Best AUC\n",
      "2022-11-28 07:26:39,812 - train - INFO -  * In epoch 0013, loss=0.693, acc=0.732, AUC=0.775\n",
      "2022-11-28 07:26:39,814 - train - INFO -  * In epoch 0013, loss=0.693, acc=0.732, AUC=0.775, Best AUC\n",
      "2022-11-28 07:26:39,863 - train - INFO -  * In epoch 0014, loss=0.693, acc=0.739, AUC=0.790\n",
      "2022-11-28 07:26:39,865 - train - INFO -  * In epoch 0014, loss=0.693, acc=0.739, AUC=0.790, Best AUC\n",
      "2022-11-28 07:26:39,922 - train - INFO -  * In epoch 0015, loss=0.693, acc=0.756, AUC=0.802\n",
      "2022-11-28 07:26:39,924 - train - INFO -  * In epoch 0015, loss=0.693, acc=0.756, AUC=0.802, Best AUC\n",
      "2022-11-28 07:26:39,977 - train - INFO -  * In epoch 0016, loss=0.693, acc=0.764, AUC=0.811\n",
      "2022-11-28 07:26:39,979 - train - INFO -  * In epoch 0016, loss=0.693, acc=0.764, AUC=0.811, Best AUC\n",
      "2022-11-28 07:26:40,031 - train - INFO -  * In epoch 0017, loss=0.693, acc=0.771, AUC=0.818\n",
      "2022-11-28 07:26:40,033 - train - INFO -  * In epoch 0017, loss=0.693, acc=0.771, AUC=0.818, Best AUC\n",
      "2022-11-28 07:26:40,084 - train - INFO -  * In epoch 0018, loss=0.693, acc=0.776, AUC=0.824\n",
      "2022-11-28 07:26:40,086 - train - INFO -  * In epoch 0018, loss=0.693, acc=0.776, AUC=0.824, Best AUC\n",
      "2022-11-28 07:26:40,139 - train - INFO -  * In epoch 0019, loss=0.693, acc=0.774, AUC=0.827\n",
      "2022-11-28 07:26:40,140 - train - INFO -  * In epoch 0019, loss=0.693, acc=0.774, AUC=0.827, Best AUC\n",
      "2022-11-28 07:26:40,192 - train - INFO -  * In epoch 0020, loss=0.693, acc=0.775, AUC=0.829\n",
      "2022-11-28 07:26:40,194 - train - INFO -  * In epoch 0020, loss=0.693, acc=0.775, AUC=0.829, Best AUC\n",
      "2022-11-28 07:26:40,237 - train - INFO - Best Weight Confirmed : 20'th epoch\n",
      "2022-11-28 07:26:40,239 - root - INFO - Task Complete\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "train(\n",
    "    model,\n",
    "    train_data,\n",
    "    n_epoch=CFG.n_epoch,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    use_wandb=False,\n",
    "    weight=CFG.weight_basepath,\n",
    "    logger=logger.getChild(\"train\"),\n",
    ")\n",
    "logger.info(\"Task Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(logging_conf)\n",
    "use_cuda = torch.cuda.is_available() and CFG.use_cuda_if_available\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "if not os.path.exists(CFG.output_dir):\n",
    "    os.makedirs(CFG.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = inference(model, test_data, logger=logger.getChild(\"infer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.detach().cpu().numpy()\n",
    "pd.DataFrame({\"prediction\": pred}).to_csv(\n",
    "        os.path.join(CFG.output_dir, \"plus_test_submission.csv\"), index_label=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGCN ìž„ë² ë”© ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16896"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16896, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0115, -0.0279,  0.0204,  ...,  0.0023, -0.0060, -0.0223],\n",
       "        [-0.0256, -0.0012,  0.0083,  ..., -0.0217,  0.0143,  0.0082],\n",
       "        [ 0.0099,  0.0029,  0.0068,  ...,  0.0236,  0.0211, -0.0271],\n",
       "        ...,\n",
       "        [-0.0225, -0.0119,  0.0070,  ...,  0.0156,  0.0111, -0.0194],\n",
       "        [ 0.0111,  0.0186,  0.0226,  ..., -0.0269, -0.0027,  0.0142],\n",
       "        [-0.0164, -0.0097, -0.0248,  ..., -0.0152, -0.0031, -0.0119]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.get_embedding(train_data['edge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0057, -0.0139,  0.0102, -0.0062,  0.0080,  0.0005, -0.0093, -0.0041,\n",
      "         0.0051,  0.0141, -0.0069,  0.0071, -0.0016,  0.0124,  0.0006, -0.0137,\n",
      "        -0.0029, -0.0056, -0.0054, -0.0099, -0.0043,  0.0116,  0.0059, -0.0152,\n",
      "         0.0043, -0.0113,  0.0148, -0.0084, -0.0094,  0.0088,  0.0040,  0.0085,\n",
      "        -0.0016, -0.0037,  0.0005, -0.0165, -0.0147, -0.0028,  0.0050,  0.0029,\n",
      "        -0.0117, -0.0131, -0.0002,  0.0041,  0.0038, -0.0166, -0.0069, -0.0012,\n",
      "         0.0115, -0.0040, -0.0002,  0.0011,  0.0022,  0.0125,  0.0034,  0.0015,\n",
      "        -0.0017, -0.0129, -0.0115, -0.0134,  0.0015,  0.0012, -0.0030, -0.0112],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "p1 = embed[edge_index[0]]\n",
    "p2 = embed[edge_index['A060001001']]\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riiid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì½”ë“œ : 5ê°• ì‹¤ìŠµ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# RiiiD ë°ì´í„°ì…‹ path ì„¤ì •\n",
    "RIIID_PATH = \"/opt/ml/input/data/\"\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train_df = pd.read_csv(os.path.join(RIIID_PATH, 'train_data.csv'))\n",
    "test_df = pd.read_csv(os.path.join(RIIID_PATH, 'test_data.csv'))\n",
    "submission_df = pd.read_csv(os.path.join(RIIID_PATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¼ì •ì—ì„œ í•™ìŠµ ìƒ˜í”Œì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ìœ ì €ë³„ row_idsë¥¼ ì €ìž¥\n",
    "question_row_ids_by_user_id = train_df.groupby('userID').apply(lambda x: x.index.tolist())\n",
    "question_row_ids_by_user_id.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¼ì •ì—ì„œ í•™ìŠµ ìƒ˜í”Œì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ìœ ì €ë³„ ì‹œìž‘ row_idë¥¼ ì €ìž¥\n",
    "start_row_id_by_user_id = train_df.groupby('userID').apply(lambda x: x.index[0])\n",
    "start_row_id_by_user_id.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ì¶”ê°€\n",
    "train_df['big_category'] = train_df.testId.map(lambda x:x[2]).astype(int)\n",
    "train_df['mid_category'] = train_df.testId.map(lambda x: int(x[-3:]))\n",
    "train_df['problem_num'] = train_df.assessmentItemID.map(lambda x: int(x[-3:]))\n",
    "\n",
    "# ë°ì´í„° íƒ€ìž… ë³€ê²½\n",
    "train_df['KnowledgeTag'] = train_df['KnowledgeTag'].astype(str)\n",
    "train_df['big_category'] = train_df['big_category'].astype(str)\n",
    "train_df['mid_category'] = train_df['mid_category'].astype(str)\n",
    "train_df['problem_num'] = train_df['problem_num'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate2id_dict = {}\n",
    "\n",
    "offset = 0\n",
    "\n",
    "# assessmentItemID2id\n",
    "Item2id = dict([(v, i+offset) for i, v in enumerate(train_df['assessmentItemID'].unique())])\n",
    "cate2id_dict['Item2id'] = Item2id\n",
    "offset += len(Item2id)\n",
    "\n",
    "# testId2id\n",
    "testId2id = dict([(v, i+offset) for i, v in enumerate(train_df['testId'].unique())])\n",
    "cate2id_dict['testId2id'] = testId2id\n",
    "offset += len(testId2id)\n",
    "\n",
    "# KnowledgeTag2id\n",
    "KnowledgeTag2id = dict([(v, i+offset) for i, v in enumerate(train_df['KnowledgeTag'].unique())])\n",
    "cate2id_dict['KnowledgeTag2id'] = KnowledgeTag2id\n",
    "offset += len(KnowledgeTag2id)\n",
    "\n",
    "# big_category2id\n",
    "big_category2id = dict([(v, i+offset) for i, v in enumerate(train_df['big_category'].unique())])\n",
    "cate2id_dict['big_category2id'] = big_category2id\n",
    "offset += len(big_category2id)\n",
    "        \n",
    "# mid_category2id\n",
    "mid_category2id = dict([(v, i+offset) for i, v in enumerate(train_df['mid_category'].unique())])\n",
    "cate2id_dict['mid_category2id'] = mid_category2id\n",
    "offset += len(mid_category2id)\n",
    "\n",
    "# problem_num2id\n",
    "problem_num2id = dict([(v, i+offset) for i, v in enumerate(train_df['problem_num'].unique())])\n",
    "cate2id_dict['problem_num2id'] = problem_num2id\n",
    "offset += len(problem_num2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mapping\n",
    "train_df['assessmentItemID'] = train_df['assessmentItemID'].map(Item2id)\n",
    "train_df['testId'] = train_df['testId'].map(testId2id)\n",
    "train_df['KnowledgeTag'] = train_df['KnowledgeTag'].map(KnowledgeTag2id)\n",
    "train_df['big_category'] = train_df['big_category'].map(big_category2id)\n",
    "train_df['mid_category'] = train_df['mid_category'].map(mid_category2id)\n",
    "train_df['problem_num'] = train_df['problem_num'].map(problem_num2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp ë³€ê²½í•˜ê¸°\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def convert_time(s):\n",
    "    timestamp = time.mktime(\n",
    "        datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple()\n",
    "    )\n",
    "    return int(timestamp)\n",
    "\n",
    "train_df[\"Timestamp\"] = train_df[\"Timestamp\"].apply(convert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [ #'Timestamp',\n",
    "             'answerCode']\n",
    "\n",
    "cate_cols = ['assessmentItemID', 'testId', 'KnowledgeTag', 'big_category', 'mid_category', 'problem_num'] \n",
    "\n",
    "train_df[cate_cols] = train_df[cate_cols].astype(np.int16)\n",
    "# train_df[cont_cols] = train_df[cont_cols].astype(np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"í›ˆë ¨ ë°ì´í„°ì…‹ shape : {train_df.shape}\")\n",
    "print(f\"category ê°’ë“¤ì˜ ì´ ê°¯ìˆ˜ : {offset}\")\n",
    "print(f\"category featureë“¤ì˜ column ì´ë¦„ : {cate_cols}\")\n",
    "print(f\"continuous featureë“¤ì˜ column ì´ë¦„ : {cont_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"category featureë“¤ì˜ index : {cate2id_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"trainì…‹ sequence ë°ì´í„°ë“¤ì˜ indices : {question_row_ids_by_user_id}\\n\")\n",
    "print(f\"trainì…‹ ê° sequence ë°ì´í„°ë“¤ì˜ ì²« rowì˜ index : {start_row_id_by_user_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_T:\n",
    "    seed=7\n",
    "    device='cpu'\n",
    "\n",
    "    batch_size=16\n",
    "\n",
    "    dropout=0.2\n",
    "    emb_size=100\n",
    "    hidden_size=128\n",
    "    nlayers=2\n",
    "    nheads=8\n",
    "  \n",
    "    seq_len=32\n",
    "    target_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_T.total_cate_size = offset\n",
    "CFG_T.cate_cols = cate_cols\n",
    "CFG_T.cont_cols = cont_cols\n",
    "CFG_T.start_row_id_by_user_id = start_row_id_by_user_id\n",
    "\n",
    "CFG_T.cate_vocab_size = offset\n",
    "\n",
    "CFG_T.cate_col_size = len(cate_cols)\n",
    "CFG_T.cont_col_size = len(cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ sequenceë“¤ì˜ indexë“¤ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
    "question_row_ids_by_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id_row_id_list = [(user_id, row_id)\n",
    "                             for user_id, row_ids in question_row_ids_by_user_id.items()\n",
    "                             for row_id in row_ids]\n",
    "train_user_id_row_id_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rowê°€ ê½¤ë‚˜ ëŠ˜ì–´ë‚¬ìŒì„ ì•Œ ìˆ˜ ìžˆë‹¤.\n",
    "len(train_user_id_row_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurationì— ë“±ë¡!\n",
    "CFG_T.train_user_id_row_id_list = train_user_id_row_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[cate_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class RiiidDataset(Dataset):\n",
    "    def __init__(self, df, cfg, max_seq_len=100, max_content_len=1000):        \n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_content_len = max_content_len\n",
    "        \n",
    "        self.user_id_row_id_list = cfg.train_user_id_row_id_list\n",
    "        self.start_row_id_by_user_id = cfg.start_row_id_by_user_id\n",
    "\n",
    "        self.cate_cols = cfg.cate_cols\n",
    "        self.cont_cols = cfg.cont_cols\n",
    "        \n",
    "        self.cate_features = df[self.cate_cols].values\n",
    "        self.cont_features = df[self.cont_cols].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        user_id, end_row_id = self.user_id_row_id_list[idx]\n",
    "        end_row_id += 1\n",
    "        \n",
    "        start_row_id = self.start_row_id_by_user_id[user_id]\n",
    "        start_row_id = max(end_row_id - self.max_seq_len, start_row_id) # lower bound\n",
    "        seq_len = end_row_id - start_row_id\n",
    "\n",
    "        # 0ìœ¼ë¡œ ì±„ì›Œì§„ output tensor ì œìž‘                  \n",
    "        cate_feature = torch.zeros(self.max_seq_len, len(self.cate_cols), dtype=torch.long)\n",
    "        cont_feature = torch.zeros(self.max_seq_len, len(self.cont_cols), dtype=torch.float)\n",
    "        mask = torch.zeros(self.max_seq_len, dtype=torch.int16)\n",
    "       \n",
    "        # tensorì— ê°’ ì±„ì›Œë„£ê¸°\n",
    "        cate_feature[-seq_len:] = torch.ShortTensor(self.cate_features[start_row_id:end_row_id])\n",
    "        cont_feature[-seq_len:] = torch.HalfTensor(self.cont_features[start_row_id:end_row_id])\n",
    "        mask[-seq_len:] = 1        \n",
    "            \n",
    "        # answered_correctlyê°€ cont_feature[-1]ì— ìœ„ì¹˜í•œë‹¤\n",
    "        target = torch.FloatTensor([cont_feature[-1, -1]])\n",
    "\n",
    "        # answered_correctly ë° relative_answered_correctlyëŠ”\n",
    "        # data leakageê°€ ë°œìƒí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ëª¨ë‘ ì±„ìš´ë‹¤\n",
    "        # cont_feature[-1, -1] = 0\n",
    "        # cont_feature[-1, -2] = 0\n",
    "        \n",
    "        return cate_feature, cont_feature, mask, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.user_id_row_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = RiiidDataset(train_df, CFG_T, max_seq_len=CFG_T.seq_len)\n",
    "train_loader = DataLoader(train_db, batch_size=CFG_T.batch_size, shuffle=True,\n",
    "                          drop_last=False, pin_memory=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence ë°ì´í„° í•˜ë‚˜ì˜ shapeì„ ì‚´íŽ´ë³´ìž\n",
    "for cate_x, cont_x, mask, target in train_db:\n",
    "    print(f\"category size : {cate_x.size()}\")\n",
    "    print(f\"continous size : {cont_x.size()}\")\n",
    "    print(f\"mask size : {mask.size()}\")\n",
    "    print(f\"target size : {target.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì£¼ì–´ì§€ëŠ” ë°ì´í„°ë¥¼ ì‚´íŽ´ë³´ìž\n",
    "for cate_x, cont_x, mask, target in train_loader:\n",
    "    print(f\"category size : {cate_x.size()}\")\n",
    "    print(f\"continous size : {cont_x.size()}\")\n",
    "    print(f\"mask size : {mask.size()}\")\n",
    "    print(f\"target size : {target.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“— Transformer Input / Output êµ¬í˜„\n",
    "> transformerì— ìž…ë ¥ì‹œí‚¬ inputì„ êµ¬í˜„í•˜ê³  transformerë¥¼ ê±°ì¹œ outputì„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìµœì¢… ì¶œë ¥ê°’ìœ¼ë¡œ ë°”ê¾¼ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# ìž…ë ¥ê°’\n",
    "for cate_x, cont_x, mask, target in train_loader:\n",
    "    print(f\"category size : {cate_x.size()}\")\n",
    "    print(f\"continous size : {cont_x.size()}\")\n",
    "    print(f\"mask size : {mask.size()}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸŸ¡ Category Embedding\n",
    "> ë²”ì£¼í˜• featureë¥¼ ìž„ë² ë”©í•˜ëŠ” ê³¼ì •ì„ ì‚´íŽ´ë³´ìž!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìž„ë² ë”© í¬ê¸°\n",
    "CFG_T.emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = cate_x.size(0)\n",
    "\n",
    "# ë²”ì£¼í˜• í•˜ë‚˜ë‹¹ 100ê°œë¡œ ìž„ë² ë”©ëœë‹¤!\n",
    "# [16, 32, 6] -> [16, 32, 6, 100]\n",
    "cate_emb = nn.Embedding(CFG_T.total_cate_size, CFG_T.emb_size, padding_idx=0)\n",
    "cate_embed_x = cate_emb(cate_x)\n",
    "\n",
    "cate_embed_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence ê¸¸ì´ë¥¼ ëª‡ ë°° ì¤„ì¼ ê²ƒì¸ì§€\n",
    "# ë©”ëª¨ë¦¬ ì ˆì•½ì˜ ì˜ë„ê°€ ìžˆë‹¤\n",
    "CFG_T.n_rows_per_step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_embed_normal_x = cate_embed_x.view(batch_size, CFG_T.seq_len, -1)\n",
    "cate_embed_normal_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_seq_len = cate_x.size(1) // CFG_T.n_rows_per_step\n",
    "\n",
    "# transformer inputì€ 3ì°¨ì›ì´ê³  ë§ˆì§€ë§‰ ì°¨ì›ì€ hidden ê°’ì´ë‹¤.\n",
    "# sequenceì˜ ê° ìœ„ì¹˜ì— ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìž„ë² ë”©ë˜ì–´ìžˆëŠ” ê²ƒì„ í•˜ë‚˜ë¡œ í•©ì¹˜ìž!\n",
    "# [16, 32, 6, 100] -> [16, 16, 1200]\n",
    "cate_embed_x = cate_embed_x.view(batch_size, half_seq_len, -1)\n",
    "cate_embed_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´í›„ì— ìš°ë¦¬ê°€ ì›í•˜ëŠ” hidden_sizeì˜ ì ˆë°˜ìœ¼ë¡œ projectioní•œë‹¤!\n",
    "# ì´ë ‡ê²Œ í•˜ëŠ” ì´ìœ ëŠ” ë°˜ì€ categoryë¡œ ë°˜ì€ continousìœ¼ë¡œ hidden ê°’ì„ ì±„ìš°ê¸° ìœ„í•´ì„œì´ë‹¤\n",
    "# [16, 16, 1200] -> [16, 16, 128]\n",
    "cate_proj = nn.Sequential(nn.Linear(CFG_T.emb_size * CFG_T.cate_col_size * CFG_T.n_rows_per_step, CFG_T.hidden_size),\n",
    "                          nn.LayerNorm(CFG_T.hidden_size))     \n",
    "cate_embed_x = cate_proj(cate_embed_x)\n",
    "cate_embed_x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸŸ¡ Continuous Embedding\n",
    "> ìˆ˜ì¹˜í˜• featureë¥¼ ìž„ë² ë”©í•˜ëŠ” ê³¼ì •ì„ ì‚´íŽ´ë³´ìž!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_bn = nn.BatchNorm1d(CFG_T.cont_col_size)\n",
    "\n",
    "# batchnorm 1d ì ìš©\n",
    "cont_bn_x = cont_bn(cont_x.view(-1, cont_x.size(-1)))\n",
    "cont_bn_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchnorm ì ìš© ì´í›„ ì›ëž˜ ì‚¬ì´ì¦ˆ ë³µêµ¬\n",
    "cont_bn_x = cont_bn_x.view(batch_size, -1, cont_x.size(-1))\n",
    "cont_bn_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cateì—ì„œ ì‚¬ìš©í•œ half_seq_len ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "cont_bn_x = cont_bn_x.view(batch_size, half_seq_len, -1)\n",
    "cont_bn_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²”ì£¼í˜•ê³¼ëŠ” ë‹¤ë¥´ê²Œ embeddingì—†ì´ ë°”ë¡œ projectionì„ í†µí•´ ì›í•˜ëŠ” ì‚¬ì´ì¦ˆë¡œ ì¤„ì¸ë‹¤\n",
    "# ì—¬ê¸°ì„œëŠ” embeddingì´ë¼ê³  ë¶€ë¥¸ë‹¤\n",
    "cont_emb = nn.Sequential(nn.Linear(CFG_T.cont_col_size * CFG_T.n_rows_per_step, CFG_T.hidden_size),\n",
    "                         nn.LayerNorm(CFG_T.hidden_size))\n",
    "cont_embed_x = cont_emb(cont_bn_x)\n",
    "cont_embed_x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸŸ¡ ë²”ì£¼í˜• / ìˆ˜ì¹˜í˜• embedding tensor concat\n",
    "> Transformerì— ìž…ë ¥ê°’ìœ¼ë¡œ ì£¼ë ¤ë©´ ë²”ì£¼í˜• / ìˆ˜ì¹˜í˜•ìœ¼ë¡œ embeddingëœ 2ê°œì˜ tensorë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì•¼ í•œë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ë§Žì€ featureë“¤ì´ í¬í•¨ëœ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ í•˜ë‚˜ì˜ ìž…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìžˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_embed_x.size(), cont_embed_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_emb = torch.cat([cate_embed_x, cont_embed_x], 2)\n",
    "seq_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_proj = nn.Sequential(nn.ReLU(),\n",
    "                          nn.Linear(CFG_T.hidden_size*2, CFG_T.hidden_size),\n",
    "                          nn.LayerNorm(CFG_T.hidden_size))\n",
    "\n",
    "# concatí•œ sequenceë¥¼ projectionì„ í†µí•´ ì›í•˜ëŠ” ì‚¬ì´ì¦ˆë¡œ ë³€í™˜í•œë‹¤\n",
    "# ì—¬ê¸°ì„œëŠ” embeddingì´ë¼ê³  ë¶€ë¥¸ë‹¤\n",
    "# [16, 16, 256] -> [16, 16, 128]\n",
    "seq_emb = comb_proj(seq_emb)\n",
    "seq_emb.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸŸ¡ Encoder\n",
    "> ì´ì œ ì™„ì„±ëœ ìž…ë ¥ê°’ì„ ëª¨ë¸ì— ë„£ì–´ë³´ìž!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from transformers.modeling_bert import BertConfig, BertEncoder, BertModel    \n",
    "except:\n",
    "    from transformers.models.bert.modeling_bert import BertConfig, BertEncoder, BertModel   \n",
    "\n",
    "config = BertConfig(3, # not used\n",
    "                    hidden_size=CFG_T.hidden_size,\n",
    "                    num_hidden_layers=CFG_T.nlayers,\n",
    "                    num_attention_heads=CFG_T.nheads,\n",
    "                    intermediate_size=CFG_T.hidden_size,\n",
    "                    hidden_dropout_prob=CFG_T.dropout,\n",
    "                    attention_probs_dropout_prob=CFG_T.dropout)\n",
    "\n",
    "encoder = BertEncoder(config)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Encoderë¥¼ ê±°ì¹œ tensorì˜ í¬ê¸°ëŠ” ë™ì¼í•˜ê²Œ ë‚˜ì˜¨ë‹¤\n",
    "# [16, 16, 128] -> [16, 16, 128]\n",
    "encoded_layers = encoder(seq_emb)\n",
    "sequence_output = encoded_layers[-1]\n",
    "sequence_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš°ë¦¬ê°€ í•„ìš”í•œê±´ Bertì˜ ë§ˆì§€ë§‰ queryë‹¤\n",
    "# [16, 16, 128] -> [16, 128]\n",
    "sequence_output = sequence_output[:, -1]\n",
    "sequence_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸŸ¡ ë¶„ë¥˜ ë‹¨ê³„\n",
    "> ì´ì œ ìš°ë¦¬ëŠ” ìµœì¢… ë¶„ë¥˜ë¥¼ í•´ì•¼í•œë‹¤! ì´ê±¸ ìœ„í•´ì„œ ìš°ë¦¬ëŠ” ì¶œë ¥ì˜ í¬ê¸°ë¥¼ í´ëž˜ìŠ¤ ìˆ«ìžì¸ 1ë¡œ ë³€í™˜í•œë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg():\n",
    "    return nn.Sequential(nn.Linear(CFG_T.hidden_size, CFG_T.hidden_size),\n",
    "                         nn.LayerNorm(CFG_T.hidden_size),\n",
    "                         nn.Dropout(CFG_T.dropout),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(CFG_T.hidden_size, CFG_T.target_size))\n",
    "\n",
    "reg_layer = get_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ˜ ìš°ë¦¬ëŠ” ì›í•˜ëŠ” ê²°ê³¼ê°’ì„ ì–»ì—ˆë‹¤ ðŸ˜\n",
    "# [16, 128] -> [16, 1]\n",
    "pred_y = reg_layer(sequence_output)\n",
    "pred_y.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('lgcnmodel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dcb66f4364347f1194a95291094c517d424054fad9034ad9eacecef50e85ee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
