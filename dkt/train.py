import os

import torch
import mlflow
import wandb
from args import parse_args
from src import trainer
from src.dataloader import Preprocess
from src.utils import setSeeds
import numpy as np


def main(args):
    wandb.login()
    setSeeds(args.seed)
    args.device = "cuda" if torch.cuda.is_available() else "cpu"
    preprocess = Preprocess(args)
    preprocess.load_train_data(args)
    train_data = preprocess.get_train_data()  #shape = (6698, 4, interactionìˆ˜_ê°€ë³€ì )  
                                              #shapeì˜ 6698ì€ train.csvì˜ ìœ ì € ìˆ˜
                                              #shape ì¤‘ê°„ì˜ 4ëŠ” ["testID","assessmentItemID","knowledgeTag","answerCode"]+solvesec
    train_data, valid_data = preprocess.split_data(train_data)
    # answerCodeê°€ -1ì œì™¸ testë°ì´í„°ë„ ê°™ì´ í•™ìŠµ
    # preprocess.load_train_test_data(args)
    # train_test_data = preprocess.get_train_test_data()
    # train_data = train_test_data
    
    # train_data = np.concatenate((train_data, train_test_data), axis=0)

    wandb.init(project="Sequential", entity = "recsys8", config=vars(args))
    wandb.run.name = f"{args.model}" # í‘œì‹œë˜ëŠ” ì´ë¦„ì„ ë°”ê¾¸ê³  ì‹¶ë‹¤ë©´ í•´ë‹¹ ì¤„ì„ ë°”ê¿”ì£¼ì„¸ìš”
    wandb.run.save()

    model = trainer.get_model(args).to(args.device)
    wandb.watch(model,log = 'all')
    trainer.run(args, train_data, valid_data, model)

if __name__ == "__main__":
    args = parse_args()
    os.makedirs(args.model_dir, exist_ok=True)

    # config = ConfigParser.from_args(args)
    remote_server_uri ="http://118.67.134.110:30005"
    mlflow.set_tracking_uri(remote_server_uri)
    
    experiment_name = args.model
    experiment = mlflow.get_experiment_by_name(experiment_name)
    if experiment == None:
        experiment = mlflow.set_experiment(experiment_name)
    client = mlflow.tracking.MlflowClient()
    
    run = client.create_run(experiment.experiment_id)
    run_name = "ğŸŒˆ(12/05 Mon)["+args.model+"] ì´ í”¼ì²˜: 3ê°œ / lgcn ì„ë² ë”© í”¼ì²˜ : 2ê°œ)"

    #ğŸ™‚1. FEí•  ë•Œ ì—¬ê¸° ê³ ì¹˜ì„¸ìš”!
    # columns = ['assessmentItemID', 'testId','KnowledgeTag', 
    #         'big_category', 'mid_category', 'problem_num', 'month',
    #         'dayname', 'month_mean', 'solvesec_600', 'test_mean', 'test_std', 'test_sum',
    #         'tag_mean', 'tag_std', 'tag_sum', 'big_mean', 'big_std', 'big_sum', 'user_correct_answer', 'user_total_answer', 'user_acc']
    columns = ["assessmentItemID", "testId", "KnowledgeTag", "big_category", "mid_category", "problem_num",
               "assIdx", "month", "day", "hour", "dayname", "time_category", "solvecumsum_category",
               "solvesec_3600", "test_mean", 'test_std', "tag_mean", 'tag_std', "big_mean", 'big_std',
               "user_correct_answer", "user_total_answer", "user_acc", "solvesec_cumsum", "big_category_cumconut", "big_category_user_acc", "big_category_user_std", "big_category_answer", "big_category_answer_log1p", "elo_assessmentItemID"]
    
    desc = 'ì‚¬ìš©í•œ í”¼ì²˜ :' + ', '.join(columns)

    with mlflow.start_run(run_id=run.info.run_id, run_name=run_name, description=desc):
        mlflow.set_tag("mlflow.runName", run_name)
        mlflow.set_tag('mlflow.user', 'jhl')
        params = {"lr":args.lr,
                  "epoch":args.n_epochs,
                  "hidden_dim":args.hidden_dim,
                  "seq_len":args.max_seq_len,
                  "batch":args.batch_size,
                  "drop_out":args.drop_out,
                  "patience":args.patience,
                  }
        mlflow.log_params(params)

        main(args)
