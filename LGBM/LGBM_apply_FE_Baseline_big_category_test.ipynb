{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a73ded2",
   "metadata": {},
   "source": [
    "## dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "464cf792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:58:06.029600Z",
     "start_time": "2022-12-01T15:58:02.449976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1845539, 40), (1974, 40), (260114, 40))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1845539, 39), (1845539, 1), (1974, 39), (1974, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from datetime import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from utils import custom_train_test_split, lgbm_predict, post_slack, title2filename\n",
    "\n",
    "SEED=13\n",
    "## 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî©\n",
    "data_dir = '/opt/ml/input/data' # Í≤ΩÎ°ú\n",
    "after_fe_path = os.path.join(data_dir, 'base_lgbm2.pkl')\n",
    "df = pd.read_pickle(after_fe_path)\n",
    "\n",
    "train_df = df[df.kind=='train']\n",
    "train, valid = custom_train_test_split(train_df, ratio=0.7, seed=SEED) # ÌõàÎ†®Îç∞Ïù¥ÌÑ∞ split\n",
    "test = df[df.kind=='test'] # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞\n",
    "train2 = test[test.answerCode!=-1] # ÌÖåÏä§Ìä∏Îç∞Ïù¥ÌÑ∞ ÎßàÏßÄÎßâ Ï†úÏ∂ú 2Î≤àÏ®∞Í∫ºÍπåÏßÄ ÌõàÎ†®Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©\n",
    "train = pd.concat([train,train2]) # ÌõàÎ†®Îç∞Ïù¥ÌÑ∞ Î≥ëÌï©\n",
    "train.shape, valid.shape, test.shape\n",
    "\n",
    "x_train = train.drop('answerCode',axis=1)\n",
    "y_train = train[['answerCode']]\n",
    "\n",
    "x_valid = valid.drop('answerCode',axis=1)\n",
    "y_valid = valid[['answerCode']]\n",
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be02cbcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:44:16.856172Z",
     "start_time": "2022-12-01T15:44:12.901791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1845539, 40), (1974, 40), (260114, 40))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1845539, 39), (1845539, 1), (1974, 39), (1974, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_fe_path = os.path.join(data_dir, 'after_fe_train_test_bigcategory_fe.pkl')\n",
    "df2 = pd.read_pickle(after_fe_path)\n",
    "\n",
    "train_df2 = df2[df2.kind=='train']\n",
    "train, valid = custom_train_test_split(train_df2, ratio=0.7, seed=SEED) # ÌõàÎ†®Îç∞Ïù¥ÌÑ∞ split\n",
    "test = df2[df2.kind=='test'] # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞\n",
    "train2 = test[test.answerCode!=-1] # ÌÖåÏä§Ìä∏Îç∞Ïù¥ÌÑ∞ ÎßàÏßÄÎßâ Ï†úÏ∂ú 2Î≤àÏ®∞Í∫ºÍπåÏßÄ ÌõàÎ†®Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©\n",
    "train = pd.concat([train,train2]) # ÌõàÎ†®Îç∞Ïù¥ÌÑ∞ Î≥ëÌï©\n",
    "train.shape, valid.shape, test.shape\n",
    "\n",
    "x_train2 = train.drop('answerCode',axis=1)\n",
    "y_train2 = train[['answerCode']]\n",
    "\n",
    "x_valid2 = valid.drop('answerCode',axis=1)\n",
    "y_valid2 = valid[['answerCode']]\n",
    "x_train2.shape, y_train2.shape, x_valid2.shape, y_valid2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18d3fa12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:58:10.068875Z",
     "start_time": "2022-12-01T15:58:09.769439Z"
    }
   },
   "outputs": [],
   "source": [
    "a1 = list(train_df.assessmentItemID)\n",
    "\n",
    "a2 = list(train_df2.assessmentItemID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "006f2186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:58:11.037770Z",
     "start_time": "2022-12-01T15:58:10.988283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1==a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc92ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:33:15.325962Z",
     "start_time": "2022-12-01T15:33:15.049632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uidIdx</th>\n",
       "      <th>assIdx</th>\n",
       "      <th>testIdx</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_total_answer</th>\n",
       "      <th>big_category</th>\n",
       "      <th>mid_category</th>\n",
       "      <th>problem_num</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>solvesec_3600</th>\n",
       "      <th>time_category</th>\n",
       "      <th>solvesec_cumsum</th>\n",
       "      <th>solvecumsum_category</th>\n",
       "      <th>big_category_acc</th>\n",
       "      <th>big_category_std</th>\n",
       "      <th>big_category_cumconut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5354</td>\n",
       "      <td>975</td>\n",
       "      <td>7224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202239</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5355</td>\n",
       "      <td>975</td>\n",
       "      <td>7225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275818</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>3439</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5356</td>\n",
       "      <td>975</td>\n",
       "      <td>7225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275818</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>3439</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5357</td>\n",
       "      <td>975</td>\n",
       "      <td>7225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275818</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>3439</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5358</td>\n",
       "      <td>975</td>\n",
       "      <td>7225</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275818</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>3439</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uidIdx  assIdx  testIdx  KnowledgeTag  user_correct_answer  \\\n",
       "0       0    5354      975          7224                  NaN   \n",
       "1       0    5355      975          7225                  1.0   \n",
       "2       0    5356      975          7225                  2.0   \n",
       "3       0    5357      975          7225                  3.0   \n",
       "4       0    5358      975          7225                  4.0   \n",
       "\n",
       "   user_total_answer  big_category  mid_category  problem_num  month  ...  \\\n",
       "0                  0             6             1            1      3  ...   \n",
       "1                  1             6             1            2      3  ...   \n",
       "2                  2             6             1            3      3  ...   \n",
       "3                  3             6             1            4      3  ...   \n",
       "4                  4             6             1            5      3  ...   \n",
       "\n",
       "    tag_std  tag_mean  tag_sum  solvesec_3600  time_category  solvesec_cumsum  \\\n",
       "0  0.202239  0.957333      718            0.0              0              0.0   \n",
       "1  0.275818  0.917067     3439            3.0              1              3.0   \n",
       "2  0.275818  0.917067     3439            8.0              3             11.0   \n",
       "3  0.275818  0.917067     3439            7.0              2             18.0   \n",
       "4  0.275818  0.917067     3439            7.0              2             25.0   \n",
       "\n",
       "   solvecumsum_category  big_category_acc  big_category_std  \\\n",
       "0                     0          0.711898          0.453371   \n",
       "1                     1          0.711898          0.453371   \n",
       "2                     4          0.711898          0.453371   \n",
       "3                     4          0.711898          0.453371   \n",
       "4                     4          0.711898          0.453371   \n",
       "\n",
       "   big_category_cumconut  \n",
       "0                      0  \n",
       "1                      1  \n",
       "2                      2  \n",
       "3                      3  \n",
       "4                      4  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[FEATS][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce029b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:53:22.042375Z",
     "start_time": "2022-12-01T15:53:16.831906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uidIdx</th>\n",
       "      <th>assIdx</th>\n",
       "      <th>testIdx</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_total_answer</th>\n",
       "      <th>big_category</th>\n",
       "      <th>mid_category</th>\n",
       "      <th>problem_num</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>solvesec_3600</th>\n",
       "      <th>time_category</th>\n",
       "      <th>solvesec_cumsum</th>\n",
       "      <th>solvecumsum_category</th>\n",
       "      <th>big_category_acc</th>\n",
       "      <th>big_category_std</th>\n",
       "      <th>big_category_cumconut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [uidIdx, assIdx, testIdx, KnowledgeTag, user_correct_answer, user_total_answer, big_category, mid_category, problem_num, month, day, dayname, hour, user_acc, test_mean, test_sum, test_std, tag_std, tag_mean, tag_sum, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x_train[FEATS],x_train2[FEATS]]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a06d94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:59:07.118374Z",
     "start_time": "2022-12-01T15:59:06.869336Z"
    }
   },
   "outputs": [],
   "source": [
    "y1=list(y_train.answerCode)\n",
    "y2=list(y_train2.answerCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2cb50c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:59:09.222218Z",
     "start_time": "2022-12-01T15:59:09.213712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1==y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "262a25c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:41:49.321995Z",
     "start_time": "2022-12-01T15:41:32.820531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>kind</th>\n",
       "      <th>uidIdx</th>\n",
       "      <th>assIdx</th>\n",
       "      <th>testIdx</th>\n",
       "      <th>...</th>\n",
       "      <th>time_category</th>\n",
       "      <th>solvesec_cumsum</th>\n",
       "      <th>solvecumsum_category</th>\n",
       "      <th>big_category_acc</th>\n",
       "      <th>big_category_std</th>\n",
       "      <th>big_category_cumconut</th>\n",
       "      <th>big_category_user_acc</th>\n",
       "      <th>big_category_user_std</th>\n",
       "      <th>big_category_answer</th>\n",
       "      <th>big_category_answer_log1p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userID, assessmentItemID, testId, answerCode, Timestamp, KnowledgeTag, kind, uidIdx, assIdx, testIdx, user_correct_answer, user_total_answer, user_acc, month, day, hour, dayname, big_category, problem_num, mid_category, test_mean, test_std, test_sum, tag_mean, tag_std, tag_sum, Timestamp2, solvetime, solvesec, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut, big_category_user_acc, big_category_user_std, big_category_answer, big_category_answer_log1p]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df,df2]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d006b12b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:35:16.328873Z",
     "start_time": "2022-12-01T15:35:07.404054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uidIdx</th>\n",
       "      <th>assIdx</th>\n",
       "      <th>testIdx</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_total_answer</th>\n",
       "      <th>big_category</th>\n",
       "      <th>mid_category</th>\n",
       "      <th>problem_num</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>solvesec_3600</th>\n",
       "      <th>time_category</th>\n",
       "      <th>solvesec_cumsum</th>\n",
       "      <th>solvecumsum_category</th>\n",
       "      <th>big_category_acc</th>\n",
       "      <th>big_category_std</th>\n",
       "      <th>big_category_cumconut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [uidIdx, assIdx, testIdx, KnowledgeTag, user_correct_answer, user_total_answer, big_category, mid_category, problem_num, month, day, dayname, hour, user_acc, test_mean, test_sum, test_std, tag_std, tag_mean, tag_sum, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df[FEATS],df2[FEATS]]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004e0c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:43:04.943512Z",
     "start_time": "2022-12-01T15:42:36.664277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>kind</th>\n",
       "      <th>uidIdx</th>\n",
       "      <th>assIdx</th>\n",
       "      <th>testIdx</th>\n",
       "      <th>...</th>\n",
       "      <th>solvesec_cumsum</th>\n",
       "      <th>solvecumsum_category</th>\n",
       "      <th>big_category_acc</th>\n",
       "      <th>big_category_std</th>\n",
       "      <th>big_category_cumconut</th>\n",
       "      <th>big_category_user_acc</th>\n",
       "      <th>big_category_user_std</th>\n",
       "      <th>big_category_answer</th>\n",
       "      <th>big_category_answer_log1p</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userID, assessmentItemID, testId, answerCode, Timestamp, KnowledgeTag, kind, uidIdx, assIdx, testIdx, user_correct_answer, user_total_answer, user_acc, month, day, hour, dayname, big_category, problem_num, mid_category, test_mean, test_std, test_sum, tag_mean, tag_std, tag_sum, Timestamp2, solvetime, solvesec, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut, big_category_user_acc, big_category_user_std, big_category_answer, big_category_answer_log1p, _merge]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(df2,indicator = True, how='left').loc[lambda x : x['_merge']!='both']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc103e3",
   "metadata": {},
   "source": [
    "## Hyper Parameter ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5bb8a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:40:20.350141Z",
     "start_time": "2022-12-01T15:40:20.346528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper parameter ÏÑ§Ï†ï\n",
    "params = {\n",
    "#     \"max_depth\": 8,  # 8,\n",
    "#     \"min_data_in_leaf\": 1000,\n",
    "    # \"feature_fraction\": 0.6,  # 0.8,\n",
    "#     \"bagging_fraction\": 0.75,\n",
    "    # \"max_cat_group\": 64,\n",
    "    \"objective\": \"binary\",\n",
    "#     \"boosting\": \"gbdt\",  # dart\n",
    "#     \"learning_rate\": 0.01,  # 0.01,\n",
    "    # \"bagging_freq\": 5,\n",
    "    \"seed\": 42,\n",
    "    # \"max_bin\": 50,\n",
    "#     \"num_leaves\": 80,  # 40,\n",
    "#     \"metric\": \"auc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db3fb0",
   "metadata": {},
   "source": [
    "## big category base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84dc8267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T15:47:02.976459Z",
     "start_time": "2022-12-01T15:46:41.964419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 6, 7, 8, 9, 11, 21, 23],\n",
       " 'üåà(12/02 Fri)[LGBM Base] ÌîºÏ≤ò: 27Í∞ú',\n",
       " 'ÏÇ¨Ïö©Îêú ÌîºÏ≤ò(27)\\nuidIdx, assIdx, testIdx, KnowledgeTag, user_correct_answer, user_total_answer, big_category, mid_category, problem_num, month, day, dayname, hour, user_acc, test_mean, test_sum, test_std, tag_std, tag_mean, tag_sum, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1208276, number of negative: 637263\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19316\n",
      "[LightGBM] [Info] Number of data points in the train set: 1845539, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654701 -> initscore=0.639767\n",
      "[LightGBM] [Info] Start training from score 0.639767\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.560243\n",
      "[200]\tvalid_0's binary_logloss: 0.551904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m lgb_x_valid \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(x_valid2[FEATS], y_valid2)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39mtitle, description\u001b[38;5;241m=\u001b[39mdesc) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m---> 46\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb_x_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb_x_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_feats_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_valid2[FEATS])\n\u001b[1;32m     57\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_valid2, np\u001b[38;5;241m.\u001b[39mwhere(preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m try_log_autologging_event(\n\u001b[1;32m    560\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    561\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs,\n\u001b[1;32m    566\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     managed_run \u001b[38;5;241m=\u001b[39m create_managed_run()\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/lightgbm.py:582\u001b[0m, in \u001b[0;36mautolog.<locals>.train\u001b[0;34m(_log_models, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [callback]\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# training model\u001b[39;00m\n\u001b[0;32m--> 582\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# If early stopping is activated, logging metrics at the best iteration\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# as extra metrics with the max step + 1.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    464\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    465\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         og_kwargs,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    474\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    475\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m         og_kwargs,\n\u001b[1;32m    480\u001b[0m     )\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    530\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    532\u001b[0m ):\n\u001b[0;32m--> 533\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jupy/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### ÌîºÏ≤ò ÏÑ§Ï†ï\n",
    "# ÏÇ¨Ïö©Ìï† Feature ÏÑ§Ï†ï\n",
    "FEATS = ['uidIdx',\n",
    "         'assIdx',\n",
    "         'testIdx',\n",
    "         'KnowledgeTag',\n",
    "         'user_correct_answer',\n",
    "         'user_total_answer',\n",
    "         'big_category',\n",
    "         'mid_category',\n",
    "         'problem_num',\n",
    "         'month','day','dayname','hour',\n",
    "         'user_acc',\n",
    "         'test_mean',\n",
    "         'test_sum',\n",
    "         'test_std',\n",
    "         'tag_std',\n",
    "         'tag_mean',\n",
    "         'tag_sum',\n",
    "         'solvesec_3600',\n",
    "         'time_category',\n",
    "         'solvesec_cumsum',\n",
    "         'solvecumsum_category',\n",
    "         'big_category_acc',\n",
    "         'big_category_std',\n",
    "         'big_category_cumconut'\n",
    "        ]\n",
    "\n",
    "cat_feats = ['uidIdx','assIdx','testIdx','KnowledgeTag','big_category','mid_category',\n",
    "             'problem_num','dayname','month','time_category','solvecumsum_category']\n",
    "cat_feats_idx = [i for i,e in enumerate(FEATS) if e in cat_feats]\n",
    "\n",
    "### ÌïôÏäµ Î∞è ÏòàÏ∏°\n",
    "\n",
    "date = datetime.now().strftime('%m/%d %a')\n",
    "title=f\"üåà({date})[LGBM Base] ÌîºÏ≤ò: {len(FEATS)}Í∞ú\"\n",
    "using_feats=\", \".join(FEATS)\n",
    "desc=f\"ÏÇ¨Ïö©Îêú ÌîºÏ≤ò({len(FEATS)})\\n{using_feats}\"\n",
    "cat_feats_idx, title, desc\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "lgb_x_train = lgb.Dataset(x_train[FEATS], y_train)\n",
    "lgb_x_valid = lgb.Dataset(x_valid[FEATS], y_valid)\n",
    "\n",
    "with mlflow.start_run(run_name=title, description=desc) as run:\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        lgb_x_train,\n",
    "        valid_sets=[lgb_x_valid],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=3200,\n",
    "        categorical_feature=cat_feats_idx,\n",
    "        early_stopping_rounds=200,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(x_valid2[FEATS])\n",
    "    acc = accuracy_score(y_valid2, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid2, preds)\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    mlflow.log_metric(\"VAL AUC\",auc)\n",
    "    mlflow.log_metric(\"VAL Set SEED\",SEED)\n",
    "    model_run_id=run.info.run_id\n",
    "    post_slack(\"done\")\n",
    "    print(f\"{model_run_id=}\")\n",
    "    file_name = title2filename(title)\n",
    "    lgbm_predict(test, model, FEATS, f'{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afbdcdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:51:18.609584Z",
     "start_time": "2022-12-01T14:50:18.057847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 6, 7, 8, 9, 11, 21, 23],\n",
       " 'üåà(12/01 Thu)[LGBM Base] ÌîºÏ≤ò: 27Í∞ú',\n",
       " 'ÏÇ¨Ïö©Îêú ÌîºÏ≤ò(27)\\nuidIdx, assIdx, testIdx, KnowledgeTag, user_correct_answer, user_total_answer, big_category, mid_category, problem_num, month, day, dayname, hour, user_acc, test_mean, test_sum, test_std, tag_std, tag_mean, tag_sum, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_cumconut')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1208276, number of negative: 637263\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19298\n",
      "[LightGBM] [Info] Number of data points in the train set: 1845539, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654701 -> initscore=0.639767\n",
      "[LightGBM] [Info] Start training from score 0.639767\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.541637\n",
      "[200]\tvalid_0's binary_logloss: 0.534939\n",
      "[300]\tvalid_0's binary_logloss: 0.533198\n",
      "[400]\tvalid_0's binary_logloss: 0.532723\n",
      "[500]\tvalid_0's binary_logloss: 0.531957\n",
      "[600]\tvalid_0's binary_logloss: 0.531247\n",
      "[700]\tvalid_0's binary_logloss: 0.53145\n",
      "[800]\tvalid_0's binary_logloss: 0.531576\n",
      "Early stopping, best iteration is:\n",
      "[643]\tvalid_0's binary_logloss: 0.531134\n",
      "VALID AUC : 0.8074321271614572 ACC : 0.7310030395136778\n",
      "\n",
      "model_run_id='9e8f1b0a79c34f928c7796130067e552'\n",
      "writing prediction : output/12_01_Thu_LGBM_Base_ÌîºÏ≤ò_27Í∞ú.csv\n"
     ]
    }
   ],
   "source": [
    "### ÌîºÏ≤ò ÏÑ§Ï†ï\n",
    "# ÏÇ¨Ïö©Ìï† Feature ÏÑ§Ï†ï\n",
    "FEATS = ['uidIdx',\n",
    "         'assIdx',\n",
    "         'testIdx',\n",
    "         'KnowledgeTag',\n",
    "         'user_correct_answer',\n",
    "         'user_total_answer',\n",
    "         'big_category',\n",
    "         'mid_category',\n",
    "         'problem_num',\n",
    "         'month','day','dayname','hour',\n",
    "         'user_acc',\n",
    "         'test_mean',\n",
    "         'test_sum',\n",
    "         'test_std',\n",
    "         'tag_std',\n",
    "         'tag_mean',\n",
    "         'tag_sum',\n",
    "         'solvesec_3600',\n",
    "         'time_category',\n",
    "         'solvesec_cumsum',\n",
    "         'solvecumsum_category',\n",
    "         'big_category_acc',\n",
    "         'big_category_std',\n",
    "         'big_category_cumconut'\n",
    "        ]\n",
    "\n",
    "cat_feats = ['uidIdx','assIdx','testIdx','KnowledgeTag','big_category','mid_category',\n",
    "             'problem_num','dayname','month','time_category','solvecumsum_category']\n",
    "cat_feats_idx = [i for i,e in enumerate(FEATS) if e in cat_feats]\n",
    "\n",
    "### ÌïôÏäµ Î∞è ÏòàÏ∏°\n",
    "\n",
    "date = datetime.now().strftime('%m/%d %a')\n",
    "title=f\"üåà({date})[LGBM Base] ÌîºÏ≤ò: {len(FEATS)}Í∞ú\"\n",
    "using_feats=\", \".join(FEATS)\n",
    "desc=f\"ÏÇ¨Ïö©Îêú ÌîºÏ≤ò({len(FEATS)})\\n{using_feats}\"\n",
    "cat_feats_idx, title, desc\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "lgb_x_train = lgb.Dataset(x_train[FEATS], y_train)\n",
    "lgb_x_valid = lgb.Dataset(x_valid[FEATS], y_valid)\n",
    "\n",
    "with mlflow.start_run(run_name=title, description=desc) as run:\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        lgb_x_train,\n",
    "        valid_sets=[lgb_x_valid],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=3200,\n",
    "        categorical_feature=cat_feats_idx,\n",
    "        early_stopping_rounds=200,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(x_valid[FEATS])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    mlflow.log_metric(\"VAL AUC\",auc)\n",
    "    mlflow.log_metric(\"VAL Set SEED\",SEED)\n",
    "    model_run_id=run.info.run_id\n",
    "    post_slack(\"done\")\n",
    "    print(f\"{model_run_id=}\")\n",
    "    file_name = title2filename(title)\n",
    "    lgbm_predict(test, model, FEATS, f'{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ï†úÏ∂ú mlflow Îì±Î°ù\n",
    "# Ï†úÏ∂úÏãú\n",
    "LB_AUC=\n",
    "run_id = model_run_id\n",
    "mlflow.start_run(run_id=run_id)\n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "mlflow.log_metric(\"LB AUC\",LB_AUC)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4c8e4",
   "metadata": {},
   "source": [
    "## big category per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7985f7be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:54:03.993139Z",
     "start_time": "2022-12-01T14:53:03.787908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 6, 7, 8, 9, 11, 21, 23],\n",
       " 'üåà(12/01 Thu)[LGBM Base userÎ≥Ñ] ÌîºÏ≤ò: 29Í∞ú',\n",
       " 'ÏÇ¨Ïö©Îêú ÌîºÏ≤ò(29)\\nuidIdx, assIdx, testIdx, KnowledgeTag, user_correct_answer, user_total_answer, big_category, mid_category, problem_num, month, day, dayname, hour, user_acc, test_mean, test_sum, test_std, tag_std, tag_mean, tag_sum, solvesec_3600, time_category, solvesec_cumsum, solvecumsum_category, big_category_acc, big_category_std, big_category_user_acc, big_category_user_std, big_category_cumconut')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1208276, number of negative: 637263\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19808\n",
      "[LightGBM] [Info] Number of data points in the train set: 1845539, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654701 -> initscore=0.639767\n",
      "[LightGBM] [Info] Start training from score 0.639767\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.480857\n",
      "[200]\tvalid_0's binary_logloss: 0.470515\n",
      "[300]\tvalid_0's binary_logloss: 0.467732\n",
      "[400]\tvalid_0's binary_logloss: 0.467005\n",
      "[500]\tvalid_0's binary_logloss: 0.466398\n",
      "[600]\tvalid_0's binary_logloss: 0.466485\n",
      "[700]\tvalid_0's binary_logloss: 0.466833\n",
      "[800]\tvalid_0's binary_logloss: 0.467351\n",
      "Early stopping, best iteration is:\n",
      "[664]\tvalid_0's binary_logloss: 0.466268\n",
      "VALID AUC : 0.8579496447200887 ACC : 0.7745694022289767\n",
      "\n",
      "model2_run_id='797a3c67d31c48569c5c7d31b57e0765'\n",
      "writing prediction : output/12_01_Thu_LGBM_Base_userÎ≥Ñ_ÌîºÏ≤ò_29Í∞ú.csv\n"
     ]
    }
   ],
   "source": [
    "### ÌîºÏ≤ò ÏÑ§Ï†ï\n",
    "# ÏÇ¨Ïö©Ìï† Feature ÏÑ§Ï†ï\n",
    "FEATS = ['uidIdx',\n",
    "         'assIdx',\n",
    "         'testIdx',\n",
    "         'KnowledgeTag',\n",
    "         'user_correct_answer',\n",
    "         'user_total_answer',\n",
    "         'big_category',\n",
    "         'mid_category',\n",
    "         'problem_num',\n",
    "         'month','day','dayname','hour',\n",
    "         'user_acc',\n",
    "         'test_mean',\n",
    "         'test_sum',\n",
    "         'test_std',\n",
    "         'tag_std',\n",
    "         'tag_mean',\n",
    "         'tag_sum',\n",
    "         'solvesec_3600',\n",
    "         'time_category',\n",
    "         'solvesec_cumsum',\n",
    "         'solvecumsum_category',\n",
    "         'big_category_acc',\n",
    "         'big_category_std',\n",
    "         'big_category_user_acc',\n",
    "         'big_category_user_std',\n",
    "         'big_category_cumconut'\n",
    "        ]\n",
    "\n",
    "cat_feats = ['uidIdx','assIdx','testIdx','KnowledgeTag','big_category','mid_category',\n",
    "             'problem_num','dayname','month','time_category','solvecumsum_category']\n",
    "cat_feats_idx = [i for i,e in enumerate(FEATS) if e in cat_feats]\n",
    "\n",
    "### ÌïôÏäµ Î∞è ÏòàÏ∏°\n",
    "\n",
    "date = datetime.now().strftime('%m/%d %a')\n",
    "title=f\"üåà({date})[LGBM Base userÎ≥Ñ] ÌîºÏ≤ò: {len(FEATS)}Í∞ú\"\n",
    "using_feats=\", \".join(FEATS)\n",
    "desc=f\"ÏÇ¨Ïö©Îêú ÌîºÏ≤ò({len(FEATS)})\\n{using_feats}\"\n",
    "cat_feats_idx, title, desc\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "lgb_x_train = lgb.Dataset(x_train[FEATS], y_train)\n",
    "lgb_x_valid = lgb.Dataset(x_valid[FEATS], y_valid)\n",
    "\n",
    "with mlflow.start_run(run_name=title, description=desc) as run:\n",
    "    model2 = lgb.train(\n",
    "        params, \n",
    "        lgb_x_train,\n",
    "        valid_sets=[lgb_x_valid],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=3200,\n",
    "        categorical_feature=cat_feats_idx,\n",
    "        early_stopping_rounds=200,\n",
    "    )\n",
    "\n",
    "    preds = model2.predict(x_valid[FEATS])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    mlflow.log_metric(\"VAL AUC\",auc)\n",
    "    mlflow.log_metric(\"VAL Set SEED\",SEED)\n",
    "    model2_run_id=run.info.run_id\n",
    "    post_slack(\"done\")\n",
    "    print(f\"{model2_run_id=}\")\n",
    "    file_name = title2filename(title)\n",
    "    lgbm_predict(test, model2, FEATS, f'{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ï†úÏ∂ú mlflow Îì±Î°ù\n",
    "# Ï†úÏ∂úÏãú\n",
    "LB_AUC=\n",
    "run_id = model_run_id\n",
    "mlflow.start_run(run_id=run_id)\n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "mlflow.log_metric(\"LB AUC\",LB_AUC)\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
