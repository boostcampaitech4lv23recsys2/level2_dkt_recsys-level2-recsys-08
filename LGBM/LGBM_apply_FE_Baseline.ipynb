{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a73ded2",
   "metadata": {},
   "source": [
    "## dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from utils import custom_train_test_split, lgbm_predict, post_slack\n",
    "\n",
    "SEED=13\n",
    "## 1. ë°ì´í„° ë¡œë”©\n",
    "data_dir = '/opt/ml/input/data' # ê²½ë¡œ\n",
    "after_fe_path = os.path.join(data_dir, '[ë¶ˆëŸ¬ì˜¬ í”¼í´ íŒŒì¼ ì´ë¦„].pkl')\n",
    "df = pd.read_pickle(after_fe_path)\n",
    "\n",
    "train_df = df[df.kind=='train']\n",
    "train, valid = custom_train_test_split(train_df, ratio=0.7, seed=SEED) # í›ˆë ¨ë°ì´í„° split\n",
    "test = df[df.kind=='test'] # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "train2 = test[test.answerCode!=-1] # í…ŒìŠ¤íŠ¸ë°ì´í„° ë§ˆì§€ë§‰ ì œì¶œ 2ë²ˆì¨°êº¼ê¹Œì§€ í›ˆë ¨ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "train = pd.concat([train,train2]) # í›ˆë ¨ë°ì´í„° ë³‘í•©\n",
    "train.shape, valid.shape, test.shape\n",
    "\n",
    "x_train = train.drop('answerCode',axis=1)\n",
    "y_train = train[['answerCode']]\n",
    "\n",
    "x_valid = valid.drop('answerCode',axis=1)\n",
    "y_valid = valid[['answerCode']]\n",
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc103e3",
   "metadata": {},
   "source": [
    "## Hyper Parameter ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter ì„¤ì •\n",
    "params = {\n",
    "#     \"max_depth\": 8,  # 8,\n",
    "#     \"min_data_in_leaf\": 1000,\n",
    "    # \"feature_fraction\": 0.6,  # 0.8,\n",
    "#     \"bagging_fraction\": 0.75,\n",
    "    # \"max_cat_group\": 64,\n",
    "    \"objective\": \"binary\",\n",
    "#     \"boosting\": \"gbdt\",  # dart\n",
    "#     \"learning_rate\": 0.01,  # 0.01,\n",
    "    # \"bagging_freq\": 5,\n",
    "    \"seed\": 42,\n",
    "    # \"max_bin\": 50,\n",
    "#     \"num_leaves\": 80,  # 40,\n",
    "#     \"metric\": \"auc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db3fb0",
   "metadata": {},
   "source": [
    "## LGBM í•™ìŠµ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3171ccb",
   "metadata": {},
   "source": [
    "### í”¼ì²˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25440a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©í•  Feature ì„¤ì •\n",
    "FEATS = ['uidIdx',\n",
    "         'assIdx',\n",
    "         'testIdx',\n",
    "         'KnowledgeTag',\n",
    "         'user_correct_answer',\n",
    "         'user_total_answer',\n",
    "         'big_category',\n",
    "         'mid_category',\n",
    "         'problem_num',\n",
    "         'month','day','dayname','hour',\n",
    "         'user_acc',\n",
    "         'test_mean',\n",
    "         'test_sum',\n",
    "         'test_std',\n",
    "         'tag_std',\n",
    "         'tag_mean',\n",
    "         'tag_sum',\n",
    "         'solvesec_3600',\n",
    "         'time_category',\n",
    "         'solvesec_cumsum',\n",
    "         'solvecumsum_category'\n",
    "        ]\n",
    "\n",
    "cat_feats = ['uidIdx','assIdx','testIdx','KnowledgeTag','time_category','solvecumsum_category']\n",
    "cat_feats_idx = [i for i,e in enumerate(FEATS) if e in cat_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760babac",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9701b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime('%m/%d %a')\n",
    "title=f\"ğŸŒˆ({date})[LGBM ê¸°ì¡´ 8012 ì¬í˜„] í”¼ì²˜: {len(FEATS)}ê°œ\"\n",
    "using_feats=\", \".join(FEATS)\n",
    "desc=f\"ì‚¬ìš©ëœ í”¼ì²˜({len(FEATS)})\\n{using_feats}\"\n",
    "cat_feats_idx, title, desc\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "lgb_x_train = lgb.Dataset(x_train[FEATS], y_train)\n",
    "lgb_x_valid = lgb.Dataset(x_valid[FEATS], y_valid)\n",
    "\n",
    "with mlflow.start_run(run_name=title, description=desc) as run:\n",
    "    model5 = lgb.train(\n",
    "        params, \n",
    "        lgb_x_train,\n",
    "        valid_sets=[lgb_x_valid],\n",
    "        verbose_eval=100,\n",
    "        num_boost_round=3200,\n",
    "        categorical_feature=cat_feats_idx\n",
    "    #     early_stopping_rounds=200,\n",
    "    )\n",
    "\n",
    "    preds = model5.predict(x_valid[FEATS])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    mlflow.log_metric(\"VAL AUC\",auc)\n",
    "    mlflow.log_metric(\"VAL Set SEED\",SEED)\n",
    "    model5_run_id=run.info.run_id\n",
    "    post_slack(\"done\")\n",
    "    lgbm_predict(test, model5, FEATS, 'LGBM_ê¸°ì¡´8102_ì¬í˜„ì„±í…ŒìŠ¤íŠ¸_train_testë¥¼í•©ì³ì„œ_í•œë²ˆì—feí•¨ìˆ˜í†µê³¼í•˜ë„ë¡_ìˆ˜ì •.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf3d5d",
   "metadata": {},
   "source": [
    "### ì œì¶œ mlflow ë“±ë¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œì‹œ\n",
    "LB_AUC=0.8107\n",
    "run_id = model3_run_id\n",
    "mlflow.start_run(run_id=run_id)\n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "mlflow.log_metric(\"LB AUC\",LB_AUC)\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
